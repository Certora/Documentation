Diagnostic Tools
================


(tac-reports)=
## TAC Reports

% TODO  write this -- https://certora.atlassian.net/browse/DOC-355

% TODO: writing "verification condition" should write "rule", or what?..

{term}`TAC` Reports provide an under-the-hood view on a given verification
condition as well as the result that the Prover produced for that verification
condition, if available. There are four variants of TAC reports, one each for the
results SAT, UNSAT, TIMEOUT, and one that contains no information from the
result. In the following, we will discuss these variants one by one. We will
begin with the TAC report without Prover result information, since its
constituents are present in the other variants as well.

## Plain TAC reports


```{figure} rebase-tac-report-plain-annotated.png
:name: plain-tac-report
:alt: Plain TAC report example
:align: center

Example of a plain TAC report (with annotations in red)
```

At the center of a TAC report is a visualization of the verification condition's
{term}`control flow graph` (CFG).[^nested-cfg] There are two kinds of nodes.
Regular nodes and call nodes. Regular nodes have a solid outline, while call
nodes have a dashed outline. Clicking on a regular nodes will made the source
code box (discussed below) focus on the corresponding source code; clicking on a
call node will replace the currently displayed CFG with the CFG that belongs to
the called method. 

```{note}
Only external calls are explicit in the TAC report's CFGs. Internal calls are 
inlined on the TAC source code level.
```

[^nested-cfg]: Strictly speaking, there is a set of CFGs available for each
    verification condition. Every external call has its own CFG, and the CFGs
    are related by call nodes which lead from a call site to the corresponding
    callee's CFG. Intuitively, this set can be viewed as one CFG with nested 
    sub-CFGs for the calls.

The upper-mid left part of a TAC report contains the TAC source code. The
details of the TAC language are outside the scope of this documentation.
Generally speaking, TAC is generated by compiler-style transformations of the
EVM bytecode together with the CVL specification. Many patterns from EVM
bytecode are retained in TAC, however inlining of functions and various
simplifications have already happened. Especially since the source code in the
TAC reports is taken from a stage directly before the SMT solving. The source
code is useful because it "speaks the truth", i.e., it has all the
summarizations and inlinings and optimizations already applied, it is very close
to what the SMT solver sees. 

Some commands in the TAC source code have pointers to the program or
specification code that the TAC program was created from. These are the
commands with a dotted underline; the source code location they have been
translated from is revealed on hovering with the mouse over such a command, as
displayed in the image below.


```{figure} source-pointer-on-hover-annotated.png
:name: source-pointer-on-hover
:alt: Source pointer shown on hover
:align: center

source pointer is shown on hover over TAC commands with dotten underline
```

The call-based navigation on the mid-right side of the report lists all the
calls in the TAC program. Each call is identified by a number. After the number
there is a number of arrows, indicating the nesting depth of the call, i.e.
calls from spec get one arrow, a call from a method body with one arrow gets two
arrows, etc.; see the picture below for an example. After the arrows the name of
the called method is given. Each of these calls is clickable and will lead to
the corresponding CFG.

```{figure} call-depth-arrows.png
:name: call-depth-arrows
:alt: Arrows indicating depth of call
:align: center
:height: 300

arrows indicating the "depth" of a call in the call links
```

% TODO: ok to show these Aave/delvtech|element method names in this picture?

At the bottom of the TAC report are the successor and predecessor relations of
the CFG on a per-block/per-node basis. These are usually not useful for the tool
user, so we will ignore them in the remainder of this document.

## SAT TAC reports


```{figure} sat-tac-report-plain.png
:name: sat-tac-report
:align: center

example TAC report for a run with a SAT result
```

After a rule was checked with a {term}`SAT` outcome, a TAC report like the one
in the above figure is generated. In addition to the components of the plain TAC
report, this report variant illustrates the {term}`model` (aka. counterexample)
that is provided by the SMT solver to witness violation of an `assert` command
(or the fulfillment of a `satisfy` command). The model is illustrated by a path
in the control flow graph and a valuation of the TAC program variables.

The path corresponds to the {term}`call trace` from the
[report](verification-report); it is the path through the program that is taken
on the input given by the counterexample.  It is indicated by red arrows and
nodes in the control flow graph.

The valuation is given in the box in the top right; it lists every variable in
the TAC program along with the value that it has under the model that the SMT
solver found.


```{note}
The names of the TAC variables are often not helpful for understanding what they 
mean. The valuation can nonetheless be useful for variables whose meaning is 
clear from context (e.g. operations they occur in, or the source pointers).
```

## UNSAT TAC reports

By default, the TAC report in the UNSAT case is the same as the plain TAC
report. This changes when a `--coverage_info` option other than "NONE" is
chosen.

% TODO write about unsat core TAC reports, link to the other unsat core doc

## Timeout TAC reports

In case of a Timeout result, the TAC report contains additional information that
is meant to help with preventing the timeout in the future.

```{figure} timeout-tac-report-plain.png
:name: timeout tac report plain
:align: center

example TAC report for a run with a Timeout result
```

% TODO picture with yellow and green nodes (if possible) and highlights in source box

The figure above shows a TAC report that was generated from a Certora Prover run
that timed out. Compared to the plain TAC report, additional information is
available in three ways:
 - Explanations and statistics are given in the box in the top right corner 
   (double click to expand).
 - CFG nodes have colors that indicate how the Prover run went and which parts 
   are difficult.
 - In the source code box there is difficulty information given by color 
   highlights to some commands and by additional text giving difficulty 
   statistics on difficult code blocks .



### Statistics- and explanation-box

The box in the top right of the Timeout TAC reports contains explanations on the
node colors as well as statistical information pertaining to how difficult the
program is to solve and what might be the particularly difficult parts.   

```{figure} timeout-tac-report-explanation-box.png
:name: timeout tac report explanation box
:align: center

Timeout TAC report with expanded statistics- and explanation-box
```

The above picture shows the expanded statistics- and explanation box. Currently,
the contents of the box are the following:
 - explanations for each color used in the CFG nodes
 - general difficulty-related statistics pertaining to the whole program
 - per-call breakdown of the "path count" statistic
 - per-call breakdown of the "number of nonlinear operations" statistic


 

### Split- and heuristic difficulty-coloring

### TAC source code box

There is a brief explanation of how to use TAC reports in the 
[webinar on timeouts](https://www.youtube.com/watch?v=mntP0_EN-ZQ).
